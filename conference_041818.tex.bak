\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Based on deep-learning apporach to real-time identify traffic of VoIP applications\\
{\footnotesize \textsuperscript{*}Note: Sub-titles are not captured in Xplore and
should not be used}
\thanks{Identify applicable funding agency here. If none, delete this.}
}

\author{\IEEEauthorblockN{1\textsuperscript{st} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address}
\and
\IEEEauthorblockN{2\textsuperscript{nd} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address}
\and
\IEEEauthorblockN{3\textsuperscript{rd} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address}
\and
\IEEEauthorblockN{4\textsuperscript{th} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address}
\and
\IEEEauthorblockN{5\textsuperscript{th} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address}
\and
\IEEEauthorblockN{6\textsuperscript{th} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address}
}

\maketitle

\begin{abstract}
  With their high service quality and low price cost, VoIP applications win most of the users' favor. However, owing to the convenience of VoIP service, there are some social tragedies caused by fraud call. In order to make VoIP applications serve human better, it is important to keep VoIP applications under supervision. The upgrade of VoIP technology makes the traditional identification method inefficient, so it is more difficult to manage VoIP applications. In this paper, we propose a generic approach, which can identify VoIP traffic from all kinds of VoIP applications (non-encrypted and encrypted). Using this approach, we can also determine source application of captured VoIP traffic in real time. Our approach uses deep learning to extract statistical features for matrix which is composed of several continuous RTP or RTCP packets. It is able to find most useful features using deep learning approach, in the meantime, it can get rid of human effort in exploring features. In addition, we design a real-time identification system to verify the efficiency of our approach. The evaluation results show that our approach can identify VoIP applications accurately.
\end{abstract}

\begin{IEEEkeywords}
VoIP, traffic identification, deep learning, real-time.
\end{IEEEkeywords}

\section{Introduction}
\label{intro}
Recently, with their price advantage, VoIP (Voice over Internet Protocol) applications have been used more and more among the people. In some private networks, network traffic generated by VoIP applications need to be controlled. It is necessary to identify VoIP application traffic accurately. VoIP applications can provide many convenient services, like anonymous service, multi-line calls. Because of the convenience of these services, VoIP applications are used for fraud by some unruly elements. So determine VoIP traffic comes from which application can help us deal with emergencies.

However, the upgrading of VoIP technology makes identification task more difficult. In most of VoIP applications, SIP or H.323 protocol is used in call connection phase, RTP/RTCP protocol is used in voice transmission phase. Encryption technologies such as SSL/TLS, SIPS, WEP and WAP/WAP2 may be used to encrypt call connections, SRTP/SRTCP may be used to encrypt voice transmission. Identifying VoIP traffic is getting harder and harder. It is urgent to find a more effective and more generic way for identifying VoIP traffic.
%And VoIP applications are different from applications like HTTP, DNS, which use standard port.

In this paper, our main goal is finding a way to determine VoIP traffic's original application. It is impossible to identify traffic using call signaling which is encrypted using SSL/TLS, WEP and WAP/WAP2 in call connection phase. We adopt a method that only relies on the traffic generated during the voice transmission phase. Deep Learning provides us with ideas to solve the this problem.
%Zhanyi Wang \cite{1} proposed the application of Deep Learning on traffic identification.
The features extracted by deep learning are not only more reliable than the features extracted by humans, but also greatly improve the identification efficiency.

The concept of real time mentioned in this article is relative, if we can identify the source application of a call flow in an acceptable time, we think it is real time. Many researchers identify VoIP applications by extracting the characteristics of bidirectional voice transmission stream, it is not feasible for real-time identification. Therefore, we proposed a method to extract features for multiple continuous packets generated within seconds or even a few milliseconds.
%we can do feature extraction for the traffic generated within seconds or even a few milliseconds and apply the extracted features to real-time identification.
%We need to extract the most accurate features in the shortest possible time for VoIP traffic identification. To make the features more reliable, we proposed a method to extract features for multiple continuous packets.

The remainder of this paper is structured as follows. In section \ref{sec:relatedwork}, we describes the previously published related work.  In section \ref{sec:methodology}, there is a brief introduction to several methods used in this paper. Then we present the architecture of our real-time identification system in section \ref{sec:architecture}. In sections \ref{sec:relatedwork}, \ref{sec:relatedwork} and \ref{sec:relatedwork}, we describe the dataset and model used for deep learning, and how to perform real-time identification. The performance evaluation is shown in section \ref{sec:relatedwork}. The conclusion is shown in section \ref{sec:relatedwork}.

\section{Related Work}
\label{sec:relatedwork}
Khan, F. I. U. A. (2008) \cite{2} proposed a generic technique for VoIP traffic detection. They analyze the characteristics of packet-inter arrival time, packet size and rate of packet exchange in the whole voice transmission stream. Their main goal is to use generic features to distinguish between VoIP traffic and other types of traffic. The following conclusions are given in this paper: Average packets/Sec rate is greater in VoIP as compared to other applications; Average packet size in bytes is small in VoIP as compared to other applications. Their method is important in detecting VoIP traffic, but it can not be used for identify specific VoIP applications. Our main goal is to further identify specific original application for VoIP traffic.

Yildirim, T., \& Radcliffe, P. J. (2010, August) \cite{3} proposed a method that can detect VoIP traffic quickly, this method is aiming at improving VoIP service quality. Packets whose length in range of 60 to 150 bytes are treated as VoIP packets. The article is mainly aimed at improving the quality of VoIP services, so detecting efficiency has a higher priority than accuracy. This method can not be used for identify specific VoIP applications either, and the length of traffic generated by latest VoIP application is no longer limited to 60-150 bytes. In our research, the length of packets of several applications is more than 200. But it still is a simple and effective way to help us extract VoIP traffic in all kinds of network traffic.

Gomes, J. V., In$\acute{a}$cio, P. R., Pereira, M., Freire, M. M., \& Monteiro, P. P. (2013) \cite{4} proposed a method that identifies Peer-to-Peer VoIP sessions using entropy and codec properties. The mechanism classifies the VoIP flows, in real-time, based on the speech codec used in the session. Classifier does not use the lengths of the packets individually, it explores their level of heterogeneity using entropy to emphasize such feature. Different codecs used by different VoIP applications are listed, and the lengths of the payloads and the entropy of the first three minutes of VoIP sessions using different CBR or VBR codecs are drawn in this paper. The results of the performance evaluation shows this method can identify VoIP sessions accurately. The proposed method is able to identify VoIP applications in real-time, it is similar to our goal. 3 minutes are still too long to identify VoIP traffic for our requirement. We want to improve the effectiveness and accuracy using deep learning.

Alshammari, R., \& Zincir-Heywood, A. N. (2015) \cite{5} structure feature sets for traffic excluding payload. The traffic is complete bidirectional flow between client and server. In this paper, fiat(forward inter-arriaval time), biat(backward inter-arriaval time), fpkt(forward packet length), bpkt(backward packet length), proto and duration etc. are listed. And researchers are trying to train dataset using 3 supervised learning methods, C5.0, Ada Boost and Genetic Programming. The results show C5.0 is better than the others, for Skype, it achieves 100\% DR, the other VoIP application achieves more than 90\% too. This paper lists so many features for complete voice flow, we want to collect more features just for a short voice flow using deep learning, so that classifier can be more accurate and effective.

Zhanyi Wang \cite{1} proposed the application of Deep Learning on traffic identification. They think it is difficult and time-consuming to find the features for traffic identification. They propose a method based on neural network and deep learning, and they apply the method to protocol classification and unknown protocol identification, all of the results show the deep learning method works very well on protocol classification. Their method provide us a idea to identify application of VoIP traffic in real time.

There are several differences between our method and above methods: 1) we use deep learning to extract feature set. The feature set is more credible than extracted by human; 2) IP and UDP header are not included in our dataset. The reason why we do not use them is the development of NAT technology and network proxy technology make the identification based on IP address limited and VoIP applications always use non-specific port; 3) we only use a limited number of packets to identify application. This is the basis of our real-time identification. Based on these differences, our method has several advantages, automatic generation of feature set, generic for non-encrypted and encrypted VoIP applications, used for real-time identification.

\section{Methodology}
\label{sec:methodology}
In order to identify a flow's original application, we need to extract the features of the traffic generated at the beginning of the VoIP call. Most of the VoIP applications use RTP/RTCP protocol to transfer data, the ability to identify a single packet is low. In this paper, we extract features for a object (we use k-packet to denote it in the following) which consists of several continuous VoIP packets. According to our investigation, the number of packets generated by VoIP applications can reach tens or even hundreds in a second, which proves our method is feasible. We did some researches for 10 VoIP applications. According to our analysis, there are 8 VoIP applications (AltCall, Jumblo, Xlite, Zoiper UUCall, Eyebeam, ExpressTalk and Bria) using constant-length packets for transmission. 2 VoIP applications (Skype and KCCall) use variable-length packets. The length number used by Skype is completely random. About KCCall, it only limits to 2 values. Most of them use single payload type except KCCall which uses 2 types. The above analysis can divide 10 VoIP applications into several classes, our goal is to use deep learning techniques to extract as many features as possible for k-packet, including basic features such as length of packet, type of payload, and other features can not be observed by humans. The features learned by deep learning can classify them more detailed.

We apply supervised learning method to train the dataset. Constructing and labeling dataset is troublesome for researchers. In order to get raw VoIP traffic, we deploy several computers installed with VoIP applications in real network. To label them accurately, we adopt some traffic capture tools which are process-based. They can help us get pure raw traffic for each application, so we can label traffic using the name of VoIP application. Next problem is how to construct our training dataset with raw traffic data and ensure the dataset is uniform as soon as possible. We design a way that uses sliding window to select k-packet into training dataset, the next step is randomized in [1, k]. In Section~\ref{sec:trafficcollectionandprocessing}, we will introduce how to construct dataset detailed.

In order to select a suitable deep learning model for our training phase, we compared several classic deep neural network models. We considered factors such as hardware requirements and time-consuming and so on, we selected AlexNet to training our dataset finally. The training is carried out on a machine with 24G RAM and a quad-core Intel processor of 3.6GHz. The machine is equipped with NVIDIA GeForce GTX 1070(8GB) to accelerate computing. CUDA Toolkit 8.0 is used in our experiment to support parallel computing.

Collecting raw traffic data, constructing and labeling dataset and training dataset are offline, they are the basis for identifying traffic online in real time. In real-time identification phase, we parse the \{srcIP, dstIP, srcPort, dstPort\} in IP and UDP header, the quad-tuple will be used to separate flows as a key. We generate a k-packet for each flow with their specific key, then we identify the k-packet with the offline identification model. For each flow with specific key, the identification result will be saved as the value of the key. The \{key, value\} is saved into our database, we can identify the following traffic using their quad-tuple.
%the key to generate a k-packet. We identify the k-packet with the offline identification model. The identification result will be saved as the value The following traffic whose key equals we use <srcIP, dstIP, srcPort, dstPort> as key, we capture k-packet following the quad-tuple. After we get the identification result for a k-packet,
%About training, we apply several classic deep neural network models to train our dataset. For images, the identification rate of deep neural networks has exceeded the rate of human eyes. We believe that deep neural network can achieve good result in VoIP identification field.

\section{Architecture}
\label{sec:architecture}
In this section, we introduce the architecture of real-time identification system. There are 2 main phases in our architecture, offline training and online identification. We introduce the architecture of these two phases separately.
%In this section, we introduce the architecture of real-time identification system and give a basic overview of the 2 main phases in the architecture. There are 2 main phases in our architecture, training phase and identification phase. Our architecture is shown in Figure~\ref{fig:architecture}

\subsection{Offline Training}
In offline training phase, we use 10 kinds of traffic of captured VoIP applications training deep leaning model, our goal is to maximize the accuracy of training and validation data. There are mainly 2 procedures, data preprocessing and model training. In preprocessing, we label our dataset firstly, random select k-packet with sliding window secondly. In the procedure of converting k-packets into matrices, we remove IP header and UDP header and normalize them. Then we input these matrices and label vector into deep learning model. The training process is maximizing the loss function to find an optimal function for identification. The output of training process is the identification model that we will use in real-time identification. In evaluation procedure, We evaluate the identification model by calculating loss and accuracy for evaluation data which needs to be normalized too. Offline training detailed in Figure~\ref{fig:offline_architecture.eps}.

\begin{figure}[htp]
\begin{center}
\includegraphics[width=0.8\textwidth]{offline_architecture.eps}
\caption{Architecture of offline training.}\label{fig:offline_architecture.eps}
\end{center}
\end{figure}
\subsection{Online Identification}
Online identification is the final part of our system. In this phase, there are 2 operations for every packet. We parse IP address and UDP port as its key for every packet. We maintain a map database for these keys. If the value of the corresponding key has been set, the value is the identification result of the packet. If the value is null, we search the key in pending flows database and add this packet into corresponding pending flow. When a pending flow is ready to be identified, it will be identified by identification model and set the identification result in map database. In Figure~\ref{fig:online_architecture.eps}, the number of pending flow key\_3 reaches k, it is ready to be identified. We show 2 captured packets whose keys are key\_1 and key\_2, packet corresponding to key\_1 will be identify with map database in real time, packet corresponding to key\_2 will be appended into its pending flow.

%Identification phase is the final part of our system. In this phase, we use identification model to identify the k-packet captured in real-time. This phase includes 3 procedures, inspection of VoIP traffic, preprocessing and identification. In inspection procedure, we detect beginning of a VoIP connection. After this, we capture a k-packet and convert it to matrix in preprocessing procedure. Then we input the matrix into identification model, the identification model give us the result which is a specific VoIP application.
\begin{figure}[htp]
\begin{center}
\includegraphics[width=0.8\textwidth]{online_architecture.eps}
\caption{Architecture of online identification.}\label{fig:online_architecture.eps}
\end{center}
\end{figure}

\section{Traffic Collection and Processing}
\label{sec:trafficcollectionandprocessing}
Traffic collection is the beginning of all of the works. In order to get raw traffic of 10 VoIP applications mentioned above, we deploy 8 computers installed 10 kinds of VoIP applications. We installed 6 computers with Windows operating system, the others 2 computers installed with Linux operating system, because there are only 4 applications can be installed on Linux platform. We can establish ordinary VoIP calls among them, and all of them can dial the phone number directly. There are 4 cell phones ready to be called.


%Traffic collection is the beginning of all of the works. In order to get traffic of 10 VoIP applications mentioned above, we deploy 8 computers installed 10 kinds of VoIP applications. We installed 6 computers with Windows operating system, the others 2 computers installed with Linux operating system, because there are only 4 applications can be installed on Linux platform. We can establish ordinary VoIP calls among them, and they can dial the phone number directly. There are 4 cell phones ready to be called.

For the purpose of labeling data easier, we use the process-based capture tool QPA under Windows operating system; We use tcpdump to capture traffic based on port, which can be known after process occupied. Additional analysis is done using the well-known Wireshark network packet analysis tool. QPA provide GUI application under Windows OS, it is easy to use for capturing traffic for a single process. Under Linux platform, we need to get pid of a process, then we use command like "tcpdump -i eth\_name trans\_protocol port pid" to capture traffic of a specific process. Because of process-based and port-based capture, it is easy to label raw traffic with their process name.

We need to construct our training dataset with captured raw traffic. We process the raw traffic to k-packets, we use sliding window to select k-packet into our dataset. The length of the window is k, and the next step is random. It ensures that our datasets will not be overly similar or overly vague. Figure~\ref{fig:dataset} shows how we select 4 k-packets for $k=10$. In this paper, a variety of identification models are trained according to different k, including 2, 4, 6, 8, 10, 20, 40 and 100. We have 3 steps to convert a k-packet to matrix. 1) Remove IP and UDP header; 2) Convert the k-packet to matrix on the basis of ASCII code; 3) Normalize the matrix. The length of VoIP packets is generally small around 50\~210, so we set column of the matrix to 256. The row of the matrix is k, indicating a k-packet includes k packets.

%Before training with deep learning model, we need to preprocess packets to k-packet. In this paper, a variety of identification models are trained according to different k, including 2, 4, 6, 8, 10, 20, 40 and 100. To get different datasets for each k value, we set the size of sliding window equals k, and select random step length value from 1-k. Figure~\ref{fig:dataset} shows how we building dataset for $k=10$. There are 3 steps that we convert a k-packet to matrix. 1) Remove IP and UDP header; 2) Convert the k-packet to matrix on the basis of ASCII code; 3) Normalize the matrix. The length of VoIP packets is generally small around 50\~210, so we set column of the matrix to 256. The row of the matrix is k, indicating a k-packet includes k packets.
\begin{figure}[htp]
\begin{center}
\includegraphics[width=0.9\textwidth]{dataset.eps}
\caption{How to process raw traffic to get k-packets(k=10).}\label{fig:dataset}
\end{center}
\end{figure}

\section{Learning using Deep-Learning model}
\label{sec:learningusingdeeplearningmodel}
\subsection{Deep Learning model}
With the rise of artificial intelligence technology, more and more excellent deep learning models appear. The oldest is CNN (Convolutional Neural Network) proposed by~\cite{6}. The LeNet is a development of the CNN proposed by~\cite{7}.~\cite{8} published an incredible neural network called AlexNet, this model get the best performance in the ImageNet competition held in 2012.~\cite{9} proposed VGG. The GoogleNet make a daring attempt in the design of the network, which proposed by~\cite{10}.~\cite{11} proposed ResNet, which has a deeper network structure up to 152 layers.

We compare CNN, AlexNet and GoogleNet with k set to 20 using a small part of dataset. The accuracy of CNN is above 94\%, the accuracies of AlexNet and GoogleNet are close to 1. GoogleNet costs more time and space than the other 2 models. We did comprehensive consideration about accuracy, efficiency, hardware requirements, data set size and other conditions, we decide to use AlexNet in the next further training. With the increase of dataset, we can use the models with a deeper network structure such as GoogleNet and ResNet.
\subsection{AlexNet}
AlexNet includes 8 layers, consists of 5 convolution layers and 3 fully connected layers. AlexNet adopts relu (Rectified Linear Units) function as its activation function, and it applies dropout in learning phase. These 2 ideas shortens the training cycle so that it increases efficiency.

The inputs of AlexNet are matrices with size of k$\times$l, where k is number of packets used for k-packet, l is the column of matrix, we use 256. In our experiment, several k values we select are not fit into AlexNet. So we do some adjustment on original AlexNet, we adjust the filter kernel to 5$\times$5, and we change the padding type to same in each layer. The first 7 layers in the structure dropout the neural according to a probability of 0.5, the first 2 fully connected layers are activated using the relu activation function, and the last fully connected layer is activated using softmax function. We only keep a max-pooling operation in the last convolution layer, the pooling window set to 2$\times$2.
\subsection{Learning}
We use softmax function as the activation function of the last layer. There are 10 types of VoIP traffic in our experiment, we calculate the posterior probability for unknown VoIP traffic. Softmax function shows as
\begin{equation}
\hat P({V_i}) = softmax({V_i}) = \frac{{{e^{{V_i}}}}}{{\sum\limits_{j = 1}^n {{e^{{V_j}}}} }}
\end{equation}
where $({V_1},{V_2},{\rm{\cdot\cdot\cdot,}}{V_i},{\rm{\cdot\cdot\cdot}},{V_n})$ denotes the matrix to be inputted into softmax in the 8th layer; $(\hat P({V_1}),\hat P({V_2}),{\rm{\cdot\cdot\cdot}},\hat P({V_i}),{\rm{\cdot\cdot\cdot}},\hat P({V_n}))$ is the output of the 8th layer, it is posterior probability distribution of k-packet, it is a vector with size of $1 \times n$; n is 10 in our experiment, it denotes the number of training VoIP application classes.

During the training, we train data to find the most optimal weights to maximize the likelihood estimate of k-packet. To minimize the CCE (categorical cross-entropy), we have the formula as follow,
\begin{equation}
CCE({V_i}) =  - \sum\limits_{i = 1}^n {P({V_i}) \times \log (\hat P({V_i}))}
\end{equation}
where $P({V_i})$ denotes the real probability ${V_i}$, it is the target matrix generated according to the labels corresponding to the training data. $P({V_j})=1$, where j is the label corresponding to VoIP application that this k-packet belongs.$P({V_i})=0$,where $i \ne j$.

We use SGD (Stochastic Gradient Descent) optimizer to minimize the loss function in this paper, and apply nesterov momentum to update gradient after every iteration. The formula of gradient increment shown as follow,
\begin{equation}
\Delta {X_t} = \tau {M_{t - 1}} - \eta \nabla f({X_{t - 1}} + \tau {M_{t - 1}})
\end{equation}
where ${\tau}$ denotes the factor of momentum, ${\eta}$ denotes learning rate. ${g_t} = \nabla f({X_{t - 1}} + \tau {M_{t - 1}})$ is the gradient of transition point, where $\Delta {X_t}$ denotes the real decreasing displacement, ${X_t}$ denotes the position at time t, ${M_t}$ denotes the momentum ate time t.

In our experiment, learning rate will decay after each epoch, decay rule shown as:
\begin{equation}
{\eta _i} = {\eta _{i - 1}} \times \frac{1}{{1 + \rho  \times i}}
\end{equation}
where ${\rho }$ denotes the decay factor, i denotes the number of epoch.

\subsection{Feature Set}
Our method is to get a more precise feature set for identifying VoIP traffic. The feature set extracted by deep learning is unreadable. We use these feature set to train SVM, random forest, decision tree and naive bayes. With this feature set, they all achieved good accuracy. We compare the accuracy of using our feature set and the feature set used in some previous research in Section~\ref{sec:experimentresults}.

\section{Real-time identification}
\label{sec:realtimeidentification}
In this section, we introduce how to real-time identify VoIP applications with identification model. To capture the VoIP traffic in real time, we design a real-time traffic capturer. This capturer can filter RTP/RTCP traffic and separate flows by IP address and UDP port.

In most of VoIP applications, H.323 and SIP protocol are used for establishing and ending VoIP call. They both support call hold, call transfer, call forwarding, call waiting and some other supplementary services. So there are some researchers devote to monitor VoIP traffic based on call control signaling. It is no longer feasible to monitor VoIP traffic based on call control signaling. Here are several reasons: 1) SIP and H.323 protocols have their own development, and they support both UDP and TCP now. 2) The usage of ports is more and more irregular, it makes many identification methods useless. 3) More and more VoIP applications are encrypted to the traffic of call control. 4) For some VoIP applications, the server used for communication and that used for transmitting call control signaling are different. Due to these above reasons, it is hard to monitor VoIP call control signaling. These reasons also are our starting point to identify VoIP traffic with RTP/RTCP packets, all applications use RTP/RTCP protocol to transfer voice data.

In order to detect VoIP voice traffic in real time, we have some rules. We only monitor the packets whose transport layer's protocol is UDP, and their packet length is less than 256. We parse the UDP packet that meets our requirements by RTP or RTCP protocol. If the UDP packet can be parsed correctly, we will process this packet with 2 operations, append it into corresponding pending flow or search identification result in map database. If it can not be parsed, we ignored it. Moreover, we ignore packet that is alone, it makes no sense to monitor it. It is easy but it works better than the way based on call control signaling.

\begin{figure}[htp]
\begin{center}
\includegraphics[width=1.0\textwidth]{flow.eps}
\caption{To separate flows by IP address and UDP port in real network.}\label{fig:flow}
\end{center}
\end{figure}

The capturer can separate pending flows and map packet into map database using their IP address and UDP port. Figure~\ref{fig:flow} shows the details to separate flows by IP address and UDP port. If a packet can not find the corresponding pending flow, we create a new pending flow and use its IP address and UDP port as key. If a packet is appended into pending flow, and the number of packet reaches k, we process k-packet to matrix. The rules are similar with above. We skip it here. We input the matrix into identification model, it will output a vector whose size is $1 \times n$,  n denotes the number of VoIP applications that our identification model can identify. The vector indicates that this k-packet's likelihood estimation for every VoIP application. The index of the maximum value in the vector is the identification result. We will set the value in map database and remove this flow in pending flows. We do not have a way to identify unknown VoIP applications for now, but we want to improve our system. So we will research the packets whose maximum likelihood is less than 0.9.


%In order to detect VoIP voice traffic in real time, we have some rules. We only monitor the packets whose transport layer's protocol is UDP, and their packet length is less than 256. We parse the UDP packet that meets our requirements by RTP or RTCP protocol. If the UDP packet can be parsed correctly, we will store its IP addresses and UDP ports, which used for the coming RTP/RTCP packets. If it can not be parsed, we ignored it. Moreover, we ignore packet that is alone, it makes no sense to monitor it. It is easy but it works better than the way based on call control signaling. Figure~\ref{fig:flow} shows the details to separate flows by IP addresses and UDP ports.


%After we capture enough k packets for identifying. The next step is to process k-packet to matrix. The rules are same as above. We skip it here. We input the matrix into identification model, it will output a vector whose size is $1 \times n$,  n denotes the number of VoIP applications that our identification model can identify. The vector indicates that this k-packet's likelihood estimation for every VoIP application. The index of the maximum value in the vector is the identification result. We do not have a way to identify unknown VoIP applications, but we want to improve our system. So we will research the packets whose maximum likelihood is less than 0.9.

\section{Performance evaluation}
\label{sec:performanceevaluation}
In this section, we first show the dataset used in our experiment. Secondly, we give the specific parameters used in the training of deep neural networks. Finally, we show the experimental results and give the evaluation of the system performance.
\subsection{Dataset}
\label{sec:dataset}
We capture traffic and divide it into 2 dataset for these 10 VoIP applications. We use dataset1 to train identification models, and we use dataset2 to examine these models. The details of dataset1 used for training shown in Table~\ref{tab:traffic}.
\begin{table}
  \caption{The details of dataset1.}
  \label{tab:traffic}
  \centering
  \begin{tabular}{p{2cm}p{3cm}p{2cm}p{2cm}}
    \toprule
    VoIP & Platform & Size(MB)& Num.(k=10)\\
    \midrule
    Skype      & Windows, Linux  & 3908.8  &  669984  \\
    UUCall      & Windows  & 2709.4  &  691566  \\
    KCCall      & Windows  & 3128.8  &  808224  \\
    ALTCall      & Windows  & 2795.2  &  692002  \\
    Jumblo      & Windows, Linux  & 3704.6  &  871468  \\
    Zoiper      & Windows, Linux  & 4418.1  &  677114  \\
    Xlite      & Windows, Linux  & 5165.3  &  638288  \\
    Eyebeam      & Windows  & 4524.7  &  616773  \\
    ExpressTalk      & Windows  & 4633.1  &  602637  \\
    Bria      & Windows  & 4476.0  &  598724  \\
    \bottomrule
  \end{tabular}
  %\caption{The details of dataset1.}
\end{table}

The forth column shows the num. of k-packet where k is 10, of course, we also process the dataset according to k is 2, 4, 6, 8 and so on. 80\% of the k-packet are used for training when 20\% used for validating. It decides the first dimension of the matrix that will be input into AlexNet model.

\subsection{Parameter Setting}
\label{sec:params}

The optimization algorithm SGD used in training phase is not adaptive for learning rate, so the setting of learning rate has a direct impact on the experimental results. We learn from the general experience of deep learning, and we adjust it according to our experimental results. The initial learning rate is set to 0.01, it decays after 2 epochs following the rules mentioned in section 6.3.  Nesterov updates based on the gradient, we set momentum factor to 0.9. We train 20 epochs using the dataset for the above 8 models, we set batch size to 100. With these parameters, we get satisfactory results for every model. Table~\ref{tab:params} shows the number and storage size of weights identification model.
\begin{table}
  \caption{The details of Alexnet parameters.}
  \label{tab:params}
  \centering
  \begin{tabular}{p{2cm}p{3cm}p{3cm}p{2cm}}
    \toprule
    Model & Input\_Shape &Num. of Parm &Size(MB)\\
    \midrule
    k=2      & ${2 \times 256 \times 1}$  & 21827434  &87.3  \\
    k=4      & ${4 \times 256 \times 1}$  & 21827434  &87.3  \\
    k=6      & ${6 \times 256 \times 1}$  & 38604650  &154.5  \\
    k=8      & ${8 \times 256 \times 1}$  & 38604650  &154.5 \\
    k=10     & ${10 \times 256 \times 1}$  & 55381866  &221.6  \\
    k=20     & ${20 \times 256 \times 1}$  & 88936298  &355.8 \\
    k=40     & ${40 \times 256 \times 1}$  & 172822378  &691.3  \\
    k=100    & ${100 \times 256 \times 1}$  & 424480618  &1619.3  \\
    \bottomrule
  \end{tabular}
  %\caption{The details of Alexnet parameters.}
\end{table}

\subsection{Experiment Results}
\label{sec:experimentresults}
The dataset listed in Section~\ref{sec:dataset} is used to train 8 models. With the parameter setting in Section~\ref{sec:params}, we get 8 identification models. The training and validating accuracies are shown in Table~\ref{tab:acc4models}.
\begin{table}
  \caption{The training and validating accuracy of 8 identification models.}
  \label{tab:acc4models}
  \centering
  \begin{tabular}{p{2cm}p{2cm}p{2cm}p{2.3cm}}
    \toprule
    Model & Loss &Train Acc. &Validate Acc.\\
    \midrule
    k=2      & 0.015865  & 0.995560  &0.996130  \\
    k=4      & 0.007670  & 0.997700  &0.997860 \\
    k=6      & 0.004933  & 0.998520  &0.999340 \\
    k=8      & 0.004393  & 0.998690  &0.999130 \\
    k=10     & 0.001159  & 0.999650  &0.999650  \\
    k=20     & 0.000546  & 0.999880  &0.999880 \\
    k=40     & 0.002920  & 0.999120  &0.999460  \\
    k=100    & 0.006689  & 0.997620  &0.998730  \\
    \bottomrule
  \end{tabular}
  %\caption{The training and validating accuracy of 8 identification models.}
\end{table}

For the above 8 identification models, we use TPR (True Positive Rate) and FPR (False Positive Rate) to evaluate them. TPR reflects the probability of positive samples are identified correctly, and FPR reflects the probability of negative samples are identified as positive samples incorrectly.TPR can be computed by Equation 5.
\begin{equation}
TPR = \frac{{TP}}{{TP + FN}}
\end{equation}
And FPR can be computed by Equation 6.
\begin{equation}
FPR = \frac{{FP}}{{FP + TN}}
\end{equation}

\begin{figure}[htp]
\begin{center}
\includegraphics[width=0.9\textwidth]{fprtpr.eps}
\caption{The performance of the 8 models shown by TPR and FPR.}\label{fig:fprtpr}
\end{center}
\end{figure}
In our experiment, the identification rate for dataset1 is close to 1. When we examine these 8 models with dataset2, there are some outliers. They can be seen in the first 4 charts shown on Figure~\ref{fig:fprtpr}, model-20 for Skype, model-4 for Xlite and so on. This is overfitting, the identification model that we trained is overfitting the dataset. In the future research, we first consider add the L1-norm and L2-norm into our model, we will merge dataset2 into dataset1 to enlarge dataset to avoid overfitting. Apart from this, these charts show good performance to most of VoIP applications.

Figure~\ref{fig:tf} shows the probability distribution of true result and false result of dataset1 and dataset2, which true result means a k-packet is identified correctly and false result means a k-packet is identified in correctly. It shows the maximum probabilities of true results are generally close to 1, and they are disperse from 0.2 to 0.98.
\begin{figure}[htp]
\begin{center}
\includegraphics[width=0.9\textwidth]{tf.eps}
\caption{The probability distribution of true result and false result.}\label{fig:tf}
\end{center}
\end{figure}
We use the feature set we extracted by neural network to train 4 machine learning models, the accuracy shows in Figure~\ref{fig:ml}. The previous research we mentioned in Section~\ref{sec:relatedwork}, they use machine learning and feature set extracted by human to identify VoIP traffic. With our feature set extracted by deep learning, the accuracy is higher than 98\%.
\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{ml.eps}
  \caption{The accuracy of 4 machine learning methods using extracted feature set.}
  \label{fig:ml}
\end{figure}

The identification efficiency of SVM is better than original AlexNet model, we deploy identification model trained by SVM into real network. We capture 100 flows for each VoIP application and identify them by these models. Time consumed by these models is shown on Table~\ref{tab:time4folws}. From this table we can see that it costs 3 seconds when k is 100, it is tolerate for a long call which lasts for a few minutes. For fraud calls which always end quickly, identification time needs to be further reduced, we have to consider using the smaller k.
\begin{table}
  \caption{The time consumed to identify 100 flows.}
  %\caption{The time consumed to identify 100 flows.}
  \label{tab:time4folws}
  \centering
  \begin{tabular}{p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}}
    \toprule
    Model & k=2 &k=4 &k=6&k=8&k=10&k=20&k=40&k=100\\
    \midrule
    Time(s)      & 27.55  & 20.12  &29.09&30.53&48.00&73.62&141.33&309.51  \\
    \bottomrule
  \end{tabular}
\end{table}

\section{Conclusion}
\label{sec:conclusion}
In our work, we propose a generic approach to identify VoIP application in realtime. Then we deploy this approach into a real-time identification system, and the system shows good performance. Our approach can not identify unknown VoIP applications, we will go a step further. We only deploy this system in a small network to test its real-time performance, we will deploy our system into real network and apply Storm in our system.

\section{Ease of Use}

\subsection{Maintaining the Integrity of the Specifications}

The IEEEtran class file is used to format your paper and style the text. All margins,
column widths, line spaces, and text fonts are prescribed; please do not
alter them. You may note peculiarities. For example, the head margin
measures proportionately more than is customary. This measurement
and others are deliberate, using specifications that anticipate your paper
as one part of the entire proceedings, and not as an independent document.
Please do not revise any of the current designations.

\section{Prepare Your Paper Before Styling}
Before you begin to format your paper, first write and save the content as a
separate text file. Complete all content and organizational editing before
formatting. Please note sections \ref{AA}--\ref{SCM} below for more information on
proofreading, spelling and grammar.

Keep your text and graphic files separate until after the text has been
formatted and styled. Do not number text heads---{\LaTeX} will do that
for you.

\subsection{Abbreviations and Acronyms}\label{AA}
Define abbreviations and acronyms the first time they are used in the text,
even after they have been defined in the abstract. Abbreviations such as
IEEE, SI, MKS, CGS, ac, dc, and rms do not have to be defined. Do not use
abbreviations in the title or heads unless they are unavoidable.

\subsection{Units}
\begin{itemize}
\item Use either SI (MKS) or CGS as primary units. (SI units are encouraged.) English units may be used as secondary units (in parentheses). An exception would be the use of English units as identifiers in trade, such as ``3.5-inch disk drive''.
\item Avoid combining SI and CGS units, such as current in amperes and magnetic field in oersteds. This often leads to confusion because equations do not balance dimensionally. If you must use mixed units, clearly state the units for each quantity that you use in an equation.
\item Do not mix complete spellings and abbreviations of units: ``Wb/m\textsuperscript{2}'' or ``webers per square meter'', not ``webers/m\textsuperscript{2}''. Spell out units when they appear in text: ``. . . a few henries'', not ``. . . a few H''.
\item Use a zero before decimal points: ``0.25'', not ``.25''. Use ``cm\textsuperscript{3}'', not ``cc''.)
\end{itemize}

\subsection{Equations}
Number equations consecutively. To make your
equations more compact, you may use the solidus (~/~), the exp function, or
appropriate exponents. Italicize Roman symbols for quantities and variables,
but not Greek symbols. Use a long dash rather than a hyphen for a minus
sign. Punctuate equations with commas or periods when they are part of a
sentence, as in:
\begin{equation}
a+b=\gamma\label{eq}
\end{equation}

Be sure that the
symbols in your equation have been defined before or immediately following
the equation. Use ``\eqref{eq}'', not ``Eq.~\eqref{eq}'' or ``equation \eqref{eq}'', except at
the beginning of a sentence: ``Equation \eqref{eq} is . . .''

\subsection{\LaTeX-Specific Advice}

Please use ``soft'' (e.g., \verb|\eqref{Eq}|) cross references instead
of ``hard'' references (e.g., \verb|(1)|). That will make it possible
to combine sections, add equations, or change the order of figures or
citations without having to go through the file line by line.

Please don't use the \verb|{eqnarray}| equation environment. Use
\verb|{align}| or \verb|{IEEEeqnarray}| instead. The \verb|{eqnarray}|
environment leaves unsightly spaces around relation symbols.

Please note that the \verb|{subequations}| environment in {\LaTeX}
will increment the main equation counter even when there are no
equation numbers displayed. If you forget that, you might write an
article in which the equation numbers skip from (17) to (20), causing
the copy editors to wonder if you've discovered a new method of
counting.

{\BibTeX} does not work by magic. It doesn't get the bibliographic
data from thin air but from .bib files. If you use {\BibTeX} to produce a
bibliography you must send the .bib files.

{\LaTeX} can't read your mind. If you assign the same label to a
subsubsection and a table, you might find that Table I has been cross
referenced as Table IV-B3.

{\LaTeX} does not have precognitive abilities. If you put a
\verb|\label| command before the command that updates the counter it's
supposed to be using, the label will pick up the last counter to be
cross referenced instead. In particular, a \verb|\label| command
should not go before the caption of a figure or a table.

Do not use \verb|\nonumber| inside the \verb|{array}| environment. It
will not stop equation numbers inside \verb|{array}| (there won't be
any anyway) and it might stop a wanted equation number in the
surrounding equation.

\subsection{Some Common Mistakes}\label{SCM}
\begin{itemize}
\item The word ``data'' is plural, not singular.
\item The subscript for the permeability of vacuum $\mu_{0}$, and other common scientific constants, is zero with subscript formatting, not a lowercase letter ``o''.
\item In American English, commas, semicolons, periods, question and exclamation marks are located within quotation marks only when a complete thought or name is cited, such as a title or full quotation. When quotation marks are used, instead of a bold or italic typeface, to highlight a word or phrase, punctuation should appear outside of the quotation marks. A parenthetical phrase or statement at the end of a sentence is punctuated outside of the closing parenthesis (like this). (A parenthetical sentence is punctuated within the parentheses.)
\item A graph within a graph is an ``inset'', not an ``insert''. The word alternatively is preferred to the word ``alternately'' (unless you really mean something that alternates).
\item Do not use the word ``essentially'' to mean ``approximately'' or ``effectively''.
\item In your paper title, if the words ``that uses'' can accurately replace the word ``using'', capitalize the ``u''; if not, keep using lower-cased.
\item Be aware of the different meanings of the homophones ``affect'' and ``effect'', ``complement'' and ``compliment'', ``discreet'' and ``discrete'', ``principal'' and ``principle''.
\item Do not confuse ``imply'' and ``infer''.
\item The prefix ``non'' is not a word; it should be joined to the word it modifies, usually without a hyphen.
\item There is no period after the ``et'' in the Latin abbreviation ``et al.''.
\item The abbreviation ``i.e.'' means ``that is'', and the abbreviation ``e.g.'' means ``for example''.
\end{itemize}


\subsection{Authors and Affiliations}
\textbf{The class file is designed for, but not limited to, six authors.} A
minimum of one author is required for all conference articles. Author names
should be listed starting from left to right and then moving down to the
next line. This is the author sequence that will be used in future citations
and by indexing services. Names should not be listed in columns nor group by
affiliation. Please keep your affiliations as succinct as possible (for
example, do not differentiate among departments of the same organization).

\subsection{Identify the Headings}
Headings, or heads, are organizational devices that guide the reader through
your paper. There are two types: component heads and text heads.

Component heads identify the different components of your paper and are not
topically subordinate to each other. Examples include Acknowledgments and
References and, for these, the correct style to use is ``Heading 5''. Use
``figure caption'' for your Figure captions, and ``table head'' for your
table title. Run-in heads, such as ``Abstract'', will require you to apply a
style (in this case, italic) in addition to the style provided by the drop
down menu to differentiate the head from the text.

Text heads organize the topics on a relational, hierarchical basis. For
example, the paper title is the primary text head because all subsequent
material relates and elaborates on this one topic. If there are two or more
sub-topics, the next level head (uppercase Roman numerals) should be used
and, conversely, if there are not at least two sub-topics, then no subheads
should be introduced.

\subsection{Figures and Tables}
\paragraph{Positioning Figures and Tables} Place figures and tables at the top and
bottom of columns. Avoid placing them in the middle of columns. Large
figures and tables may span across both columns. Figure captions should be
below the figures; table heads should appear above the tables. Insert
figures and tables after they are cited in the text. Use the abbreviation
``Fig.~\ref{fig}'', even at the beginning of a sentence.

\begin{table}[htbp]
\caption{Table Type Styles}
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Table}&\multicolumn{3}{|c|}{\textbf{Table Column Head}} \\
\cline{2-4}
\textbf{Head} & \textbf{\textit{Table column subhead}}& \textbf{\textit{Subhead}}& \textbf{\textit{Subhead}} \\
\hline
copy& More table copy$^{\mathrm{a}}$& &  \\
\hline
\multicolumn{4}{l}{$^{\mathrm{a}}$Sample of a Table footnote.}
\end{tabular}
\label{tab1}
\end{center}
\end{table}

%\begin{figure}[htbp]
%\centerline{\includegraphics{fig1.png}}
%\caption{Example of a figure caption.}
%\label{fig}
%\end{figure}

Figure Labels: Use 8 point Times New Roman for Figure labels. Use words
rather than symbols or abbreviations when writing Figure axis labels to
avoid confusing the reader. As an example, write the quantity
``Magnetization'', or ``Magnetization, M'', not just ``M''. If including
units in the label, present them within parentheses. Do not label axes only
with units. In the example, write ``Magnetization (A/m)'' or ``Magnetization
\{A[m(1)]\}'', not just ``A/m''. Do not label axes with a ratio of
quantities and units. For example, write ``Temperature (K)'', not
``Temperature/K''.

\section*{Acknowledgment}

The preferred spelling of the word ``acknowledgment'' in America is without
an ``e'' after the ``g''. Avoid the stilted expression ``one of us (R. B.
G.) thanks $\ldots$''. Instead, try ``R. B. G. thanks$\ldots$''. Put sponsor
acknowledgments in the unnumbered footnote on the first page.


\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,reference}

\vspace{12pt}
\color{red}
IEEE conference templates contain guidance text for composing and formatting conference papers. Please ensure that all template text is removed from your conference paper prior to submission to the conference. Failure to remove the template text from your paper may result in your paper not being published.

\end{document}
